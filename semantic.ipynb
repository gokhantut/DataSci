{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5929930274321619\n",
      "0.40415016164997786\n",
      "0.22358825939615987\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "word1 = nlp(\"cat\")\n",
    "word2 = nlp(\"monkey\")\n",
    "word3 = nlp(\"banana\")\n",
    "print(word1.similarity(word2))\n",
    "print(word3.similarity(word2))\n",
    "print(word3.similarity(word1))\n",
    "\n",
    "# cat and monkey are more similar than cat and banana\n",
    "# banana and cat are most different\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6770565478895127\n",
      "0.7276309976205778\n",
      "0.6806929391210822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h3/xdkm6d2n477__mb7yspsdy0h0gnp_h/T/ipykernel_18075/6351207.py:6: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print(word1.similarity(word2))\n",
      "/var/folders/h3/xdkm6d2n477__mb7yspsdy0h0gnp_h/T/ipykernel_18075/6351207.py:7: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print(word3.similarity(word2))\n",
      "/var/folders/h3/xdkm6d2n477__mb7yspsdy0h0gnp_h/T/ipykernel_18075/6351207.py:8: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print(word3.similarity(word1))\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "word1 = nlp(\"cat\")\n",
    "word2 = nlp(\"monkey\")\n",
    "word3 = nlp(\"banana\")\n",
    "print(word1.similarity(word2))\n",
    "print(word3.similarity(word2))\n",
    "print(word3.similarity(word1))\n",
    "\n",
    "# all of the scores are changed and increased, now moneky and banana are most closely related, \n",
    "# the other combinations scored similar to each other.\n",
    "# it is important to pick the right model for the task your are trying to achive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
